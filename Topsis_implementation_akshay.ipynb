{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7505400,
          "sourceType": "datasetVersion",
          "datasetId": 4370826
        }
      ],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Use the evaluation_results.csv file as input for this code to find topsis scroe and rank the models**"
      ],
      "metadata": {
        "id": "hvgvb8FBiypZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-criteria\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from skcriteria import mkdm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T12:12:22.677552Z",
          "iopub.execute_input": "2024-01-29T12:12:22.678384Z",
          "iopub.status.idle": "2024-01-29T12:12:23.567706Z",
          "shell.execute_reply.started": "2024-01-29T12:12:22.678341Z",
          "shell.execute_reply": "2024-01-29T12:12:23.566453Z"
        },
        "trusted": true,
        "id": "Y0MLjP17iypb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = pd.read_csv(\"/content/topsis_input.csv\")\n",
        "print(evaluation_results)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-01-29T12:07:45.540173Z",
          "iopub.execute_input": "2024-01-29T12:07:45.540612Z",
          "iopub.status.idle": "2024-01-29T12:07:45.562678Z",
          "shell.execute_reply.started": "2024-01-29T12:07:45.540573Z",
          "shell.execute_reply": "2024-01-29T12:07:45.561606Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXrraqy9iypa",
        "outputId": "805a7f45-cc91-4a85-f098-4138696f8d99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    Model  BLEU Score  Semantic Coherence  \\\n",
            "0                      google-t5/t5-large    0.352185            0.768574   \n",
            "1          pszemraj/led-base-book-summary    0.314918            0.688963   \n",
            "2  hardikJ11/bart-base-finetuned-cnn-news    0.334391            0.710904   \n",
            "3        philschmid/bart-large-cnn-samsum    0.439666            0.632890   \n",
            "4      BigSneed/autotrain-sima-2512277279    0.354885            0.771122   \n",
            "\n",
            "   Factual Accuracy  Content Coverage  Readability  \n",
            "0          0.447016          0.391597     3.856667  \n",
            "1          0.544512          0.482278     3.578667  \n",
            "2          0.390311          0.342793     3.858000  \n",
            "3          0.539266          0.288917     5.119333  \n",
            "4          0.428660          0.382961     3.981333  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Dependencies**"
      ],
      "metadata": {
        "id": "_IJAVpeNiypb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You may adjust the weights based on the importance of each criterion as per your choice**\n",
        "\n",
        "Changing the weights may change the output"
      ],
      "metadata": {
        "id": "gcRYXhtaiypc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [0.25, 0.25, 0.25, 0.25, 0.25]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T12:12:45.786083Z",
          "iopub.execute_input": "2024-01-29T12:12:45.786776Z",
          "iopub.status.idle": "2024-01-29T12:12:45.794303Z",
          "shell.execute_reply.started": "2024-01-29T12:12:45.786728Z",
          "shell.execute_reply": "2024-01-29T12:12:45.792477Z"
        },
        "trusted": true,
        "id": "J5_47x8riypc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize the scores and then calculate topsis scores and ranks for different models**"
      ],
      "metadata": {
        "id": "87CU5Ritiypc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the scores\n",
        "normalized_scores = evaluation_results.iloc[:, 1:].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "\n",
        "# Convert the normalized scores to a numpy array\n",
        "normalized_scores_array = normalized_scores.to_numpy()\n",
        "\n",
        "# Define the ideal and negative-ideal solutions\n",
        "ideal_solution = np.max(normalized_scores_array, axis=0)\n",
        "negative_ideal_solution = np.min(normalized_scores_array, axis=0)\n",
        "\n",
        "# Calculate the Euclidean distances to ideal and negative-ideal solutions\n",
        "euclidean_distances_to_ideal = np.linalg.norm(normalized_scores_array - ideal_solution, axis=1)\n",
        "euclidean_distances_to_negative_ideal = np.linalg.norm(normalized_scores_array - negative_ideal_solution, axis=1)\n",
        "\n",
        "# Calculate the TOPSIS scores\n",
        "topsis_scores = euclidean_distances_to_negative_ideal / (euclidean_distances_to_ideal + euclidean_distances_to_negative_ideal)\n",
        "\n",
        "# Add TOPSIS scores to your evaluation_results DataFrame\n",
        "evaluation_results[\"TOPSIS Score\"] = topsis_scores\n",
        "\n",
        "# Rank based on TOPSIS scores\n",
        "evaluation_results[\"Rank\"] = evaluation_results[\"TOPSIS Score\"].rank(ascending=False)\n",
        "\n",
        "# Display the final evaluation_results DataFrame\n",
        "print(evaluation_results)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T12:18:26.131489Z",
          "iopub.execute_input": "2024-01-29T12:18:26.131990Z",
          "iopub.status.idle": "2024-01-29T12:18:26.161767Z",
          "shell.execute_reply.started": "2024-01-29T12:18:26.131942Z",
          "shell.execute_reply": "2024-01-29T12:18:26.160227Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfpYpeGpiypc",
        "outputId": "66b1acaa-6a39-470e-e164-a0bbcd4a31c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    Model  BLEU Score  Semantic Coherence  \\\n",
            "0                      google-t5/t5-large    0.352185            0.768574   \n",
            "1          pszemraj/led-base-book-summary    0.314918            0.688963   \n",
            "2  hardikJ11/bart-base-finetuned-cnn-news    0.334391            0.710904   \n",
            "3        philschmid/bart-large-cnn-samsum    0.439666            0.632890   \n",
            "4      BigSneed/autotrain-sima-2512277279    0.354885            0.771122   \n",
            "\n",
            "   Factual Accuracy  Content Coverage  Readability  TOPSIS Score  Rank  \n",
            "0          0.447016          0.391597     3.856667      0.478583   3.0  \n",
            "1          0.544512          0.482278     3.578667      0.489552   2.0  \n",
            "2          0.390311          0.342793     3.858000      0.276876   5.0  \n",
            "3          0.539266          0.288917     5.119333      0.547647   1.0  \n",
            "4          0.428660          0.382961     3.981333      0.472200   4.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the output csv file**"
      ],
      "metadata": {
        "id": "vD4kxZrAiypc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results.to_csv(\"topsis_results.csv\", index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T12:20:59.270632Z",
          "iopub.execute_input": "2024-01-29T12:20:59.271134Z",
          "iopub.status.idle": "2024-01-29T12:20:59.282153Z",
          "shell.execute_reply.started": "2024-01-29T12:20:59.271091Z",
          "shell.execute_reply": "2024-01-29T12:20:59.281011Z"
        },
        "trusted": true,
        "id": "Iv_HpjRXiypc"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}